{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svd2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1vHB9v4yybIFUfNwym+kH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonbarron/svd2/blob/master/svd2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQFRINe_VOcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax\n",
        "import jax.numpy as np\n",
        "\n",
        "@jax.jit\n",
        "def svd2(A):\n",
        "  # Adapted from https://lucidar.me/en/mathematics/singular-value-decomposition-of-a-2x2-matrix/\n",
        "\n",
        "  def f(X):\n",
        "    a = X[:,0,1] + X[:,1,0]\n",
        "    b = X[:,0,0] - X[:,1,1]\n",
        "    z = np.sqrt((b + 1j*a)/np.sqrt(a**2 + b**2))\n",
        "    z_real = np.real(z)\n",
        "    z_imag = np.imag(z)\n",
        "    q = (1 + 1/(z_real**2 + z_imag**2))\n",
        "    cos = 0.5 * z_real * q\n",
        "    sin = 0.5 * z_imag * q\n",
        "    Y = np.reshape(np.stack([cos, -sin, sin, cos], -1), [-1, 2, 2])\n",
        "    return Y\n",
        "\n",
        "  AAT = np.einsum('nij,nkj->nik', A, A) \n",
        "  U = f(AAT)\n",
        "\n",
        "  trace = AAT[:,0,0] + AAT[:,1,1]\n",
        "  d = np.sqrt((AAT[:,0,0] - AAT[:,1,1])**2 + 4*(AAT[:,0,1] * AAT[:,1,0]))\n",
        "  s = np.sqrt(0.5 * (trace[...,None] + np.stack([d, -d], -1)))\n",
        "\n",
        "  ATA = np.einsum('nji,njk->nik', A, A) \n",
        "  W = f(ATA)\n",
        "\n",
        "  D00 = np.sign(\n",
        "      (U[:,0,0] * A[:,0,0] + U[:,1,0] * A[:,1,0]) * W[:,0,0] +\n",
        "      (U[:,0,0] * A[:,0,1] + U[:,1,0] * A[:,1,1]) * W[:,1,0])\n",
        "  D11 = np.sign(\n",
        "      (U[:,0,1] * A[:,0,0] + U[:,1,1] * A[:,1,0]) * W[:,0,1] +\n",
        "      (U[:,0,1] * A[:,0,1] + U[:,1,1] * A[:,1,1]) * W[:,1,1])\n",
        "  VT = np.reshape(np.stack([\n",
        "    W[:,0,0] * D00, W[:,1,0] * D00,\n",
        "    W[:,0,1] * D11, W[:,1,1] * D11], -1), [-1, 2, 2])\n",
        "  \n",
        "  return U, s, VT"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF71K3JecwWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "139e9fb0-0dfd-4fa7-9d18-0ba1e6295b93"
      },
      "source": [
        "# Unit Tests.\n",
        "\n",
        "A = jax.random.normal(jax.random.PRNGKey(0), (100, 2, 2))\n",
        "A *= np.exp(jax.random.normal(jax.random.PRNGKey(0), (A.shape[0], 1, 1)))\n",
        "\n",
        "U, s, VT = svd2(A)\n",
        "U_, s_, VT_ =  np.linalg.svd(A)\n",
        "\n",
        "batch_matmul = lambda X, Y: np.einsum('nij,njk->nik', X, Y) \n",
        "\n",
        "def batch_diag(x):\n",
        "  import numpy as onp\n",
        "  D = onp.zeros([np.prod(x.shape[:-1])] + [x.shape[-1]]*2)\n",
        "  for d in range(x.shape[-1]):\n",
        "    D[...,d,d] = x[...,d]\n",
        "  return np.array(D)\n",
        "\n",
        "tol = 1e-5\n",
        "assert(np.all(np.abs(batch_matmul(U, batch_matmul(batch_diag(s), VT)) - A) < tol))\n",
        "\n",
        "U_err = np.minimum(np.min(np.abs(U_ - U), -2), np.min(np.abs(U_ + U), -2))\n",
        "assert(np.all(np.abs(U_err) < tol))\n",
        "\n",
        "VT_err = np.minimum(np.min(np.abs(VT_ - VT), -2), np.min(np.abs(VT_ + VT), -2))\n",
        "assert(np.all(np.abs(VT_err) < tol))\n",
        "\n",
        "assert(np.all(np.abs(s - s_) < tol))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jax/numpy/lax_numpy.py:1621: FutureWarning: jax.numpy reductions won't accept lists and tuples in future versions, only scalars and ndarrays\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o5AwU8zX6lE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0a0880e0-9f39-410b-8e4e-598ebc7324c6"
      },
      "source": [
        "# Profiling\n",
        "A = jax.random.normal(jax.random.PRNGKey(0), (100000, 2, 2))\n",
        "%timeit [x.block_until_ready() for x in np.linalg.svd(A)]\n",
        "%timeit [x.block_until_ready() for x in svd2(A)]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 4.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 52 ms per loop\n",
            "The slowest run took 547.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 1.39 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-ZuyuHGwN8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    }
  ]
}